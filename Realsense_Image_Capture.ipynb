{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25498031-4370-4506-82e0-ef2a40853e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyrealsense2 is installed correctly!\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "print(\"pyrealsense2 is installed correctly!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b874614-0230-4f22-8ad5-ffc1c839024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c10330ea-110f-45d4-a93a-6cd9e90c55cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Scenario (1, 2, 3):  3\n",
      "Enter Place (1, 2, 3):  1\n",
      "Enter Object (1-10):  10\n",
      "Enter Distance (X, Y, Z):  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images to: F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\Scenario_3\\Place_1\\Object_10\\Distance_16\n",
      "Press [SPACE] to capture frame or [ESC] to exit...\n",
      "Captured frame 1/33...\n",
      "Captured frame 2/33...\n",
      "Captured frame 3/33...\n",
      "Captured frame 4/33...\n",
      "Captured frame 5/33...\n",
      "Captured frame 6/33...\n",
      "Captured frame 7/33...\n",
      "Captured frame 8/33...\n",
      "Captured frame 9/33...\n",
      "Captured frame 10/33...\n",
      "Captured frame 11/33...\n",
      "Captured frame 12/33...\n",
      "Captured frame 13/33...\n",
      "Captured frame 14/33...\n",
      "Captured frame 15/33...\n",
      "Captured frame 16/33...\n",
      "Captured frame 17/33...\n",
      "Captured frame 18/33...\n",
      "Captured frame 19/33...\n",
      "Captured frame 20/33...\n",
      "Captured frame 21/33...\n",
      "Captured frame 22/33...\n",
      "Captured frame 23/33...\n",
      "Captured frame 24/33...\n",
      "Captured frame 25/33...\n",
      "Captured frame 26/33...\n",
      "Captured frame 27/33...\n",
      "Captured frame 28/33...\n",
      "Captured frame 29/33...\n",
      "Captured frame 30/33...\n",
      "Captured frame 31/33...\n",
      "Captured frame 32/33...\n",
      "Captured frame 33/33...\n",
      "Captured 33/33 frames successfully. Images saved in 'F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\Scenario_3\\Place_1\\Object_10\\Distance_16'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the base directory to store images\n",
    "base_dir = r\"F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\"\n",
    "\n",
    "# Get user input for scenario, place, object, and distance\n",
    "scenario_num = input(\"Enter Scenario (1, 2, 3): \")\n",
    "place_num = input(\"Enter Place (1, 2, 3): \")\n",
    "object_num = input(\"Enter Object (1-10): \")\n",
    "distance_val = input(\"Enter Distance (X, Y, Z): \")\n",
    "\n",
    "# Create directory path dynamically based on input\n",
    "output_dir = os.path.join(\n",
    "    base_dir, f\"Scenario_{scenario_num}\", f\"Place_{place_num}\", f\"Object_{object_num}\", f\"Distance_{distance_val}\"\n",
    ")\n",
    "\n",
    "# Check if directory exists, create it if it doesn't\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Start RealSense pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "# Enable RGB and depth streams\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "\n",
    "# Start pipeline\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Frame counter and sequence count\n",
    "frame_count = 0\n",
    "frames_to_capture = 33  # Minimum frames per sequence\n",
    "\n",
    "print(f\"Saving images to: {output_dir}\")\n",
    "print(\"Press [SPACE] to capture frame or [ESC] to exit...\")\n",
    "\n",
    "while True:\n",
    "    time.sleep(.5)\n",
    "    # Get frames\n",
    "    frame = pipe.wait_for_frames()\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    # Convert frames to numpy arrays\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Apply colormap to depth image\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    # Show RGB and depth frames\n",
    "    cv2.imshow('RGB', color_image)\n",
    "    cv2.imshow('Depth', depth_cm)\n",
    "\n",
    "    # Key press options\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    #if key == 32:  # Spacebar to capture frames\n",
    "    if frame_count < frames_to_capture:\n",
    "        # Save images to directory\n",
    "        rgb_filename = os.path.join(output_dir, f\"rgb_frame_{frame_count:04d}.png\")\n",
    "        depth_filename = os.path.join(output_dir, f\"depth_frame_{frame_count:04d}.png\")\n",
    "\n",
    "        # Save RGB and depth images\n",
    "        cv2.imwrite(rgb_filename, color_image)\n",
    "        cv2.imwrite(depth_filename, depth_cm)\n",
    "\n",
    "        frame_count += 1\n",
    "        print(f\"Captured frame {frame_count}/{frames_to_capture}...\")\n",
    "    else:\n",
    "        break\n",
    "        #print(\"Frame limit reached for this sequence.\")\n",
    "    \n",
    "    '''elif key == 27:  # ESC to exit\n",
    "        print(\"Exiting and stopping recording...\")\n",
    "        break'''\n",
    "\n",
    "# Stop pipeline and release resources\n",
    "pipe.stop()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Captured {frame_count}/{frames_to_capture} frames successfully. Images saved in '{output_dir}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1403abd-127f-4047-9ce3-bad5056ab486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrated test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd10de4-98b2-4938-affb-0b93c11058c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Scenario (1, 2, 3):  1\n",
      "Enter Place (1, 2, 3):  1\n",
      "Enter Object (1-10):  10\n",
      "Enter Distance (X, Y, Z):  11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images to: F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\Scenario_1\\Place_1\\Object_10\\Distance_11\n",
      "Capturing frames...\n",
      "Captured frame 1/33\n",
      "Captured frame 2/33\n",
      "Captured frame 3/33\n",
      "Captured frame 4/33\n",
      "Captured frame 5/33\n",
      "Captured frame 6/33\n",
      "Captured frame 7/33\n",
      "Captured frame 8/33\n",
      "Captured frame 9/33\n",
      "Captured frame 10/33\n",
      "Captured frame 11/33\n",
      "Captured frame 12/33\n",
      "Captured frame 13/33\n",
      "Captured frame 14/33\n",
      "Captured frame 15/33\n",
      "Captured frame 16/33\n",
      "Captured frame 17/33\n",
      "Captured frame 18/33\n",
      "Captured frame 19/33\n",
      "Captured frame 20/33\n",
      "Captured frame 21/33\n",
      "Captured frame 22/33\n",
      "Captured frame 23/33\n",
      "Captured frame 24/33\n",
      "Captured frame 25/33\n",
      "Captured frame 26/33\n",
      "Captured frame 27/33\n",
      "Captured frame 28/33\n",
      "Captured frame 29/33\n",
      "Captured frame 30/33\n",
      "Captured frame 31/33\n",
      "Captured frame 32/33\n",
      "Captured frame 33/33\n",
      "Captured 33 frames. Saved to 'F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\Scenario_1\\Place_1\\Object_10\\Distance_11'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Define the base directory to store images\n",
    "base_dir = r\"F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\"\n",
    "\n",
    "# Get user input for scenario, place, object, and distance\n",
    "scenario_num = input(\"Enter Scenario (1, 2, 3): \")\n",
    "place_num = input(\"Enter Place (1, 2, 3): \")\n",
    "object_num = input(\"Enter Object (1-10): \")\n",
    "distance_val = input(\"Enter Distance (X, Y, Z): \")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = os.path.join(\n",
    "    base_dir, f\"Scenario_{scenario_num}\", f\"Place_{place_num}\", f\"Object_{object_num}\", f\"Distance_{distance_val}\"\n",
    ")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Start RealSense pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "# Enable RGB and depth streams\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "\n",
    "# Start pipeline\n",
    "profile = pipe.start(cfg)\n",
    "\n",
    "# Align depth to color stream\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Optional: Create filters to smooth depth\n",
    "spatial = rs.spatial_filter()\n",
    "temporal = rs.temporal_filter()\n",
    "\n",
    "# Capture loop settings\n",
    "frame_count = 0\n",
    "frames_to_capture = 33\n",
    "\n",
    "print(f\"Saving images to: {output_dir}\")\n",
    "print(\"Capturing frames...\")\n",
    "\n",
    "while frame_count < frames_to_capture:\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Get aligned frames\n",
    "    frames = pipe.wait_for_frames()\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "    if not aligned_depth_frame or not color_frame:\n",
    "        print(\"Frame skip due to alignment issue.\")\n",
    "        continue\n",
    "\n",
    "    # Apply filters to depth\n",
    "    filtered_depth = spatial.process(aligned_depth_frame)\n",
    "    filtered_depth = temporal.process(filtered_depth)\n",
    "\n",
    "    # Convert frames to numpy arrays\n",
    "    depth_image = np.asanyarray(filtered_depth.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Apply colormap for visualization\n",
    "    depth_colormap = cv2.applyColorMap(\n",
    "        cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET\n",
    "    )\n",
    "\n",
    "    # Ensure RGB and depth_colormap match in size\n",
    "    if depth_colormap.shape != color_image.shape:\n",
    "        depth_colormap = cv2.resize(depth_colormap, (color_image.shape[1], color_image.shape[0]))\n",
    "\n",
    "    # Display both images\n",
    "    cv2.imshow('RGB', color_image)\n",
    "    cv2.imshow('Aligned Depth', depth_colormap)\n",
    "\n",
    "    # Save images\n",
    "    rgb_path = os.path.join(output_dir, f\"rgb_frame_{frame_count:04d}.png\")\n",
    "    depth_vis_path = os.path.join(output_dir, f\"depth_frame_{frame_count:04d}.png\")\n",
    "    depth_raw_path = os.path.join(output_dir, f\"depth_raw_{frame_count:04d}.npy\")\n",
    "\n",
    "    cv2.imwrite(rgb_path, color_image)\n",
    "    cv2.imwrite(depth_vis_path, depth_colormap)\n",
    "    np.save(depth_raw_path, depth_image)\n",
    "\n",
    "    print(f\"Captured frame {frame_count+1}/{frames_to_capture}\")\n",
    "    frame_count += 1\n",
    "\n",
    "    # ESC to break early\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        print(\"Capture interrupted manually.\")\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "pipe.stop()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"Captured {frame_count} frames. Saved to '{output_dir}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df6936-e790-4852-a4f4-db409f73e1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrated test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c361ac-9a7e-4c91-b718-0c8f3747cff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Scenario (1, 2, 3):  3\n",
      "Enter Place (1, 2, 3):  3\n",
      "Enter Object (1-10):  100\n",
      "Enter Distance (X, Y, Z):  d11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving images to: F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\Scenario_3\\Place_3\\Object_100\\Distance_d11\n",
      "Capturing frames...\n",
      "Saved frame 1/33\n",
      "Saved frame 2/33\n",
      "Saved frame 3/33\n",
      "Saved frame 4/33\n",
      "Saved frame 5/33\n",
      "Saved frame 6/33\n",
      "Saved frame 7/33\n",
      "Saved frame 8/33\n",
      "Saved frame 9/33\n",
      "Saved frame 10/33\n",
      "Saved frame 11/33\n",
      "Saved frame 12/33\n",
      "Saved frame 13/33\n",
      "Saved frame 14/33\n",
      "Saved frame 15/33\n",
      "Saved frame 16/33\n",
      "Saved frame 17/33\n",
      "Saved frame 18/33\n",
      "Saved frame 19/33\n",
      "Saved frame 20/33\n",
      "Saved frame 21/33\n",
      "Saved frame 22/33\n",
      "Saved frame 23/33\n",
      "Saved frame 24/33\n",
      "Saved frame 25/33\n",
      "Saved frame 26/33\n",
      "Saved frame 27/33\n",
      "Saved frame 28/33\n",
      "Saved frame 29/33\n",
      "Saved frame 30/33\n",
      "Saved frame 31/33\n",
      "Saved frame 32/33\n",
      "Saved frame 33/33\n",
      "✅ Captured 33 frames in: F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\Scenario_3\\Place_3\\Object_100\\Distance_d11\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Setup\n",
    "base_dir = r\"F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\"\n",
    "scenario_num = input(\"Enter Scenario (1, 2, 3): \")\n",
    "place_num = input(\"Enter Place (1, 2, 3): \")\n",
    "object_num = input(\"Enter Object (1-10): \")\n",
    "distance_val = input(\"Enter Distance (X, Y, Z): \")\n",
    "\n",
    "output_dir = os.path.join(\n",
    "    base_dir, f\"Scenario_{scenario_num}\", f\"Place_{place_num}\", f\"Object_{object_num}\", f\"Distance_{distance_val}\"\n",
    ")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize RealSense\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 15)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 15)\n",
    "\n",
    "profile = pipe.start(cfg)\n",
    "align = rs.align(rs.stream.color)\n",
    "\n",
    "# Filters (optional for smoother depth)\n",
    "spatial = rs.spatial_filter()\n",
    "temporal = rs.temporal_filter()\n",
    "\n",
    "frame_count = 0\n",
    "frames_to_capture = 33\n",
    "\n",
    "print(f\"Saving images to: {output_dir}\")\n",
    "print(\"Capturing frames...\")\n",
    "\n",
    "while frame_count < frames_to_capture:\n",
    "    time.sleep(0.3)\n",
    "    frames = pipe.wait_for_frames()\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "    if not color_frame or not depth_frame:\n",
    "        print(\"Skipping frame due to capture error.\")\n",
    "        continue\n",
    "\n",
    "    # Apply filters (optional)\n",
    "    depth_frame = spatial.process(depth_frame)\n",
    "    depth_frame = temporal.process(depth_frame)\n",
    "\n",
    "    # Convert frames\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "    # Scale depth for display only (avoid resizing!)\n",
    "    depth_display = cv2.convertScaleAbs(depth_image, alpha=0.03)  # More realistic contrast\n",
    "    depth_colormap = cv2.applyColorMap(depth_display, cv2.COLORMAP_JET)\n",
    "\n",
    "    # Crop depth_colormap to match RGB (only if needed)\n",
    "    if depth_colormap.shape != color_image.shape:\n",
    "        h, w = color_image.shape[:2]\n",
    "        depth_colormap = depth_colormap[:h, :w]  # Crop instead of resize\n",
    "\n",
    "    # Show\n",
    "    cv2.imshow(\"RGB\", color_image)\n",
    "    cv2.imshow(\"Aligned Depth\", depth_colormap)\n",
    "\n",
    "    # Save outputs\n",
    "    rgb_file = os.path.join(output_dir, f\"rgb_frame_{frame_count:04d}.png\")\n",
    "    depth_file = os.path.join(output_dir, f\"depth_frame_{frame_count:04d}.png\")\n",
    "            raw_file = os.path.join(output_dir, f\"depth_raw_{frame_count:04d}.npy\")\n",
    "\n",
    "    cv2.imwrite(rgb_file, color_image)\n",
    "    cv2.imwrite(depth_file, depth_colormap)\n",
    "    np.save(raw_file, depth_image)\n",
    "\n",
    "    print(f\"Saved frame {frame_count + 1}/{frames_to_capture}\")\n",
    "    frame_count += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        print(\"Early exit via ESC.\")\n",
    "        break\n",
    "\n",
    "pipe.stop()\n",
    "cv2.destroyAllWindows()\n",
    "print(f\"✅ Captured {frame_count} frames in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c300748-d07c-4f60-a137-896c02849384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2243dd15-9790-4fdd-94f7-b0e1ef3829f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "pipe.start(cfg)\n",
    "\n",
    "while True:\n",
    "    frame = pipe.wait_for_frames()\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha = 0.5), cv2.COLORMAP_JET)\n",
    "    \n",
    "    cv2.imshow('rgb', color_image)\n",
    "    cv2.imshow('depth', depth_cm)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377ef45-91e6-4ef4-9d73-4d7bb4d7c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last updated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75ead390-0daf-4d2e-b0f8-cb0c0a8d6638",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No device connected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m cfg\u001b[38;5;241m.\u001b[39menable_stream(rs\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mcolor, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m, rs\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mbgr8, \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     12\u001b[0m cfg\u001b[38;5;241m.\u001b[39menable_stream(rs\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mdepth, \u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m480\u001b[39m, rs\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mz16, \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Define the directory to store images\u001b[39;00m\n\u001b[0;32m     17\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m1 KFUPM\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m3rd Semester\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mComputer Vision\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAssignment 3\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcaptured_images2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No device connected"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Define the directory to store images\n",
    "output_dir = r\"F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\"\n",
    "\n",
    "# Check if directory exists, create it if it doesn't\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    frame = pipe.wait_for_frames()\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha = 0.5), cv2.COLORMAP_JET)\n",
    "    \n",
    "    cv2.imshow('rgb', color_image)\n",
    "    cv2.imshow('depth', depth_cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_count += 1\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 32:\n",
    "        # Save images to directory\n",
    "        rgb_filename = os.path.join(output_dir, f\"rgb_frame_{frame_count:04d}.png\")\n",
    "        depth_filename = os.path.join(output_dir, f\"depth_frame_{frame_count:04d}.png\")\n",
    "        \n",
    "        # Save RGB and depth images\n",
    "        cv2.imwrite(rgb_filename, color_image)\n",
    "        cv2.imwrite(depth_filename, depth_cm)      \n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b160a97-d09c-42b5-bf0d-3ed66ca94200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for each folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38956179-cffc-4b4c-9dc2-6743682d1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#without fixed amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ec134-e1f2-4783-96f4-b6040bfe2caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the directory to store images\n",
    "output_dir = r\"F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images\"\n",
    "\n",
    "# Check if directory exists, create it if it doesn't\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Start RealSense pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "# Enable RGB and depth streams\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start pipeline\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Frame counter for unique filenames\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Get frames\n",
    "    frame = pipe.wait_for_frames()\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    # Convert frames to numpy arrays\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Apply colormap to depth image\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    # Show RGB and depth frames\n",
    "    cv2.imshow('RGB', color_image)\n",
    "    cv2.imshow('Depth', depth_cm)\n",
    "\n",
    "    # Save images to directory\n",
    "    rgb_filename = os.path.join(output_dir, f\"rgb_frame_{frame_count:04d}.png\")\n",
    "    depth_filename = os.path.join(output_dir, f\"depth_frame_{frame_count:04d}.png\")\n",
    "\n",
    "    # Save RGB and depth images\n",
    "    cv2.imwrite(rgb_filename, color_image)\n",
    "    cv2.imwrite(depth_filename, depth_cm)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_count += 1\n",
    "\n",
    "    # Break if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Stop pipeline and release resources\n",
    "pipe.stop()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Images saved in '{output_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4405dc6-cad3-4569-983b-be159f67eb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device detected: Intel RealSense D455\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "\n",
    "ctx = rs.context()\n",
    "devices = ctx.query_devices()\n",
    "if len(devices) == 0:\n",
    "    print(\"No device connected!\")\n",
    "else:\n",
    "    for dev in devices:\n",
    "        print(\"Device detected:\", dev.get_info(rs.camera_info.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26523626-2e89-481f-a006-40139d55912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 100 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2900a5e2-ee30-4cd5-83e4-5416ad0d1c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured 100 frames. Images saved in 'F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images' directory.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import os\n",
    "\n",
    "# Define the directory to store images\n",
    "output_dir = r\"F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images\"\n",
    "\n",
    "# Check if directory exists, create it if it doesn't\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Start RealSense pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "# Enable RGB and depth streams\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Start pipeline\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Frame counter for unique filenames\n",
    "frame_count = 0\n",
    "max_frames = 100  # Capture 100 frames and stop\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    # Get frames\n",
    "    frame = pipe.wait_for_frames()\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    # Check if frames are valid\n",
    "    if not depth_frame or not color_frame:\n",
    "        continue\n",
    "\n",
    "    # Convert frames to numpy arrays\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Apply colormap to depth image\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    # Show RGB and depth frames\n",
    "    cv2.imshow('RGB', color_image)\n",
    "    cv2.imshow('Depth', depth_cm)\n",
    "\n",
    "    # Save images to directory\n",
    "    rgb_filename = os.path.join(output_dir, f\"rgb_frame_{frame_count:04d}.png\")\n",
    "    depth_filename = os.path.join(output_dir, f\"depth_frame_{frame_count:04d}.png\")\n",
    "\n",
    "    # Save RGB and depth images\n",
    "    cv2.imwrite(rgb_filename, color_image)\n",
    "    cv2.imwrite(depth_filename, depth_cm)\n",
    "\n",
    "    # Increment frame counter\n",
    "    frame_count += 1\n",
    "\n",
    "    # Break if 'q' is pressed\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        print(\"Stopping recording...\")\n",
    "        break\n",
    "\n",
    "# Stop pipeline and release resources\n",
    "pipe.stop()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Captured {frame_count} frames. Images saved in '{output_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d95ffa00-eef7-49db-a937-0ee96a03c85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth image shape: (480, 640, 3)\n",
      "Error: Depth image is 3-channel (RGB), but it should be single-channel (grayscale).\n",
      "Converted image to grayscale for processing.\n",
      "Distance at pixel (320, 240) is 0.00 meters.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to your depth image\n",
    "depth_image_path = r'F:\\1 KFUPM\\3rd Semester\\Computer Vision\\Assignment 3\\captured_images2\\depth_frame_0119.png'\n",
    "\n",
    "# Load the depth image correctly with IMREAD_UNCHANGED to preserve depth information\n",
    "depth_image = cv2.imread(depth_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# Check if the image is loaded correctly\n",
    "if depth_image is None:\n",
    "    print(\"Error: Unable to load the depth image. Check the path.\")\n",
    "    exit()\n",
    "\n",
    "# Print the shape to check dimensions\n",
    "print(f\"Depth image shape: {depth_image.shape}\")\n",
    "\n",
    "# Check if the image is still 3-channel\n",
    "if len(depth_image.shape) == 3 and depth_image.shape[2] == 3:\n",
    "    print(\"Error: Depth image is 3-channel (RGB), but it should be single-channel (grayscale).\")\n",
    "    # Convert to grayscale if needed (this may not be ideal for actual depth maps)\n",
    "    depth_image = cv2.cvtColor(depth_image, cv2.COLOR_BGR2GRAY)\n",
    "    print(\"Converted image to grayscale for processing.\")\n",
    "\n",
    "# Define camera parameters (update with your camera specs)\n",
    "focal_length = 800  # Example focal length in pixels (replace with actual value)\n",
    "baseline = 0.1  # Baseline in meters (distance between stereo cameras if applicable)\n",
    "\n",
    "# Define the target pixel to calculate the distance (example: center of the image)\n",
    "pixel_x, pixel_y = 320, 240  # Change based on the desired pixel\n",
    "\n",
    "# Check if the pixel coordinates are within the image boundaries\n",
    "height, width = depth_image.shape[:2]\n",
    "if pixel_x >= width or pixel_y >= height:\n",
    "    print(f\"Pixel coordinates ({pixel_x}, {pixel_y}) are out of bounds.\")\n",
    "    exit()\n",
    "\n",
    "# Get the depth value at the target pixel\n",
    "depth_value = depth_image[pixel_y, pixel_x]\n",
    "\n",
    "# Check if the depth value is valid and a scalar\n",
    "if np.isscalar(depth_value) and (depth_value == 0 or np.isnan(depth_value)):\n",
    "    print(f\"No valid depth information at pixel ({pixel_x}, {pixel_y}).\")\n",
    "else:\n",
    "    # If depth_value is an array with only one element, extract the value\n",
    "    if isinstance(depth_value, np.ndarray) and depth_value.size == 1:\n",
    "        depth_value = depth_value.item()\n",
    "\n",
    "    # Ensure depth_value is a valid number\n",
    "    if np.isscalar(depth_value):\n",
    "        # Calculate the real-world distance using depth value\n",
    "        real_world_distance = (depth_value * baseline) / focal_length\n",
    "\n",
    "        # Print the calculated distance\n",
    "        print(f\"Distance at pixel ({pixel_x}, {pixel_y}) is {real_world_distance:.2f} meters.\")\n",
    "    else:\n",
    "        print(f\"Unexpected depth value format at pixel ({pixel_x}, {pixel_y}).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:realsense_env]",
   "language": "python",
   "name": "conda-env-realsense_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
